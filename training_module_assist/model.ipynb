{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40523dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "035a8f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 402 employees, 28 features\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('employee_training.csv')\n",
    "print(f\"Dataset: {df.shape[0]} employees, {df.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "108db1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared dataset with 14 unique training modules\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:14: SyntaxWarning: \"\\d\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\d\"? A raw string is also an option.\n",
      "<>:14: SyntaxWarning: \"\\d\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\d\"? A raw string is also an option.\n",
      "C:\\Users\\priti.samal\\AppData\\Local\\Temp\\ipykernel_53484\\2739052293.py:14: SyntaxWarning: \"\\d\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\d\"? A raw string is also an option.\n",
      "  data['Grade_Num'] = data['Grade'].str.extract(\"(\\d+)\").astype(int)\n"
     ]
    }
   ],
   "source": [
    "data = df.copy()\n",
    "\n",
    "# Fill missing values for key training features\n",
    "data['Grade'] = data['Grade'].fillna('G1')\n",
    "data['Department'] = data['Department'].fillna('Unknown')\n",
    "data['Primary_Skill'] = data['Primary_Skill'].fillna('Unknown')\n",
    "data['Secondary_Skill'] = data['Secondary_Skill'].fillna('Unknown')\n",
    "data['Course_Category'] = data['Course_Category'].fillna('Unknown')\n",
    "data['Business_Priority'] = data['Business_Priority'].fillna('Medium')\n",
    "data['Career_Goal'] = data['Career_Goal'].fillna('Unknown')\n",
    "data['Course_Name'] = data['Course_Name'].fillna('Unknown Course')\n",
    "\n",
    "# Derive numeric grade features\n",
    "data['Grade_Num'] = data['Grade'].str.extract(\"(\\d+)\").astype(int)\n",
    "experience_map = {1: 0, 2: 0.5, 3: 1.5, 4: 3, 5: 5, 6: 7, 7: 10, 8: 12, 9: 15, 10: 18}\n",
    "data['Experience_Level'] = data['Grade_Num'].map(experience_map).fillna(0)\n",
    "\n",
    "# Add Skill_Gap_Score and Performance_Rating if available\n",
    "if 'Skill_Gap_Score' in data.columns:\n",
    "    data['Skill_Gap_Score'] = data['Skill_Gap_Score'].fillna(data['Skill_Gap_Score'].median())\n",
    "else:\n",
    "    data['Skill_Gap_Score'] = 0.3\n",
    "\n",
    "if 'Performance_Rating' in data.columns:\n",
    "    data['Performance_Rating'] = data['Performance_Rating'].fillna(data['Performance_Rating'].median())\n",
    "else:\n",
    "    data['Performance_Rating'] = 4.0\n",
    "\n",
    "# Create interaction features\n",
    "data['Grade_Skill_Interaction'] = data['Grade_Num'] * data['Skill_Gap_Score']\n",
    "data['Grade_Performance'] = data['Grade_Num'] * data['Performance_Rating']\n",
    "\n",
    "# Encode all categorical features for training\n",
    "label_encoders = {}\n",
    "for col in ['Department', 'Primary_Skill', 'Secondary_Skill', 'Course_Category', 'Business_Priority', 'Career_Goal']:\n",
    "    values = pd.concat([data[col].astype(str), pd.Series(['Unknown'])], ignore_index=True)\n",
    "    le = LabelEncoder()\n",
    "    le.fit(values)\n",
    "    data[f'{col}_Encoded'] = le.transform(data[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Encode the target course name\n",
    "target_encoder = LabelEncoder()\n",
    "data['Target'] = target_encoder.fit_transform(data['Course_Name'].astype(str))\n",
    "\n",
    "# Store reference catalog\n",
    "course_catalog = data[['Course_Name', 'Course_Category']].drop_duplicates()\n",
    "\n",
    "print(f\"Prepared dataset with {data['Target'].nunique()} unique training modules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37627514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 321 rows | Test set: 81 rows\n",
      "Unique courses in training: 14\n",
      "Total features: 12\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Feature columns with expanded attributes\n",
    "feature_cols = [\n",
    "    'Grade_Num',\n",
    "    'Experience_Level',\n",
    "    'Department_Encoded',\n",
    "    'Primary_Skill_Encoded',\n",
    "    'Secondary_Skill_Encoded',\n",
    "    'Course_Category_Encoded',\n",
    "    'Business_Priority_Encoded',\n",
    "    'Career_Goal_Encoded',\n",
    "    'Skill_Gap_Score',\n",
    "    'Performance_Rating',\n",
    "    'Grade_Skill_Interaction',\n",
    "    'Grade_Performance'\n",
    "]\n",
    "\n",
    "# Train-test split\n",
    "X, y = data[feature_cols], data['Target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features for better performance\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Train set: {X_train.shape[0]} rows | Test set: {X_test.shape[0]} rows\")\n",
    "print(f\"Unique courses in training: {y_train.nunique()}\")\n",
    "print(f\"Total features: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2e3c7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original courses: 14\n",
      "Filtered courses (≥2 samples): 14\n",
      "Removed 0 courses with single samples\n",
      "\n",
      "Train set: 321 rows\n",
      "Test set: 81 rows\n",
      "Train Accuracy: 99.4%\n",
      "Test Accuracy: 96.3%\n",
      "Overfitting Gap: 3.1%\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Filter out courses with only 1 sample (can't stratify with single samples)\n",
    "course_counts = data['Course_Name'].value_counts()\n",
    "valid_courses = course_counts[course_counts >= 2].index\n",
    "data_filtered = data[data['Course_Name'].isin(valid_courses)].copy()\n",
    "\n",
    "print(f\"Original courses: {data['Course_Name'].nunique()}\")\n",
    "print(f\"Filtered courses (≥2 samples): {data_filtered['Course_Name'].nunique()}\")\n",
    "print(f\"Removed {data['Course_Name'].nunique() - data_filtered['Course_Name'].nunique()} courses with single samples\")\n",
    "\n",
    "# Re-encode target with filtered data\n",
    "target_encoder = LabelEncoder()\n",
    "data_filtered['Target'] = target_encoder.fit_transform(data_filtered['Course_Name'].astype(str))\n",
    "\n",
    "# Update course catalog with filtered data\n",
    "course_catalog = data_filtered[['Course_Name', 'Course_Category']].drop_duplicates()\n",
    "\n",
    "# Update X and y with filtered data\n",
    "X_filtered = data_filtered[feature_cols]\n",
    "y_filtered = data_filtered['Target']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_filtered, y_filtered, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nTrain set: {X_train.shape[0]} rows\")\n",
    "print(f\"Test set: {X_test.shape[0]} rows\")\n",
    "\n",
    "\n",
    "# XGBoost optimized for better accuracy with sufficient data\n",
    "model = XGBClassifier(\n",
    "    n_estimators=800,          # More trees for better learning\n",
    "    max_depth=6,               # Deeper trees now that we have more data\n",
    "    learning_rate=0.05,        # Lower learning rate for better convergence\n",
    "    subsample=0.85,            # Use 85% of data per tree\n",
    "    colsample_bytree=0.85,     # Use 85% of features per tree\n",
    "    min_child_weight=2,        # Require 2 samples per leaf\n",
    "    gamma=0.2,                 # Moderate regularization\n",
    "    reg_alpha=0.5,             # L1 regularization\n",
    "    reg_lambda=1.5,            # L2 regularization\n",
    "    scale_pos_weight=1,        \n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    eval_metric='mlogloss',\n",
    "    early_stopping_rounds=50\n",
    ")\n",
    "\n",
    "# Train with evaluation set for early stopping\n",
    "eval_set = [(X_train_scaled, y_train), (X_test_scaled, y_test)]\n",
    "model.fit(X_train_scaled, y_train, eval_set=eval_set, verbose=False)\n",
    "\n",
    "test_predictions = model.predict(X_test_scaled)\n",
    "train_predictions = model.predict(X_train_scaled)\n",
    "test_acc = accuracy_score(y_test, test_predictions)\n",
    "train_acc = accuracy_score(y_train, train_predictions)\n",
    "\n",
    "\n",
    "print(f\"Train Accuracy: {train_acc:.1%}\")\n",
    "print(f\"Test Accuracy: {test_acc:.1%}\")\n",
    "print(f\"Overfitting Gap: {(train_acc - test_acc):.1%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "208385ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced recommendation helper with all training features\n",
    "def recommend_course(employee, top_n=3):\n",
    "    grade_value = str(employee.get('Grade', 'G3'))\n",
    "    digits = ''.join(ch for ch in grade_value if ch.isdigit())\n",
    "    grade_num = int(digits) if digits else 3\n",
    "    \n",
    "    skill_gap = employee.get('Skill_Gap_Score', 0.3)\n",
    "    performance = employee.get('Performance_Rating', 4.0)\n",
    "\n",
    "    profile = {\n",
    "        'Grade_Num': grade_num,\n",
    "        'Experience_Level': experience_map.get(grade_num, 0.0),\n",
    "        'Skill_Gap_Score': skill_gap,\n",
    "        'Performance_Rating': performance,\n",
    "        'Grade_Skill_Interaction': grade_num * skill_gap,\n",
    "        'Grade_Performance': grade_num * performance\n",
    "    }\n",
    "\n",
    "    for col in ['Department', 'Primary_Skill', 'Secondary_Skill', 'Course_Category', 'Business_Priority', 'Career_Goal']:\n",
    "        encoder = label_encoders[col]\n",
    "        value = str(employee.get(col, 'Unknown') or 'Unknown')\n",
    "        if value not in encoder.classes_:\n",
    "            value = 'Unknown'\n",
    "        profile[f'{col}_Encoded'] = int(encoder.transform([value])[0])\n",
    "\n",
    "    X_new = pd.DataFrame([profile])[feature_cols]\n",
    "    X_new_scaled = scaler.transform(X_new)\n",
    "\n",
    "    probabilities = model.predict_proba(X_new_scaled)[0]\n",
    "    top_indices = np.argsort(probabilities)[::-1][:top_n]\n",
    "\n",
    "    recommendations = []\n",
    "    for idx in top_indices:\n",
    "        course_name = target_encoder.inverse_transform([idx])[0]\n",
    "        confidence = probabilities[idx]\n",
    "        catalog_row = course_catalog[course_catalog['Course_Name'] == course_name]\n",
    "        course_category = catalog_row['Course_Category'].iloc[0] if not catalog_row.empty else 'Unknown'\n",
    "        recommendations.append({\n",
    "            'Course_Name': course_name,\n",
    "            'Course_Category': course_category,\n",
    "            'Confidence': confidence\n",
    "        })\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "711ebc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting recommendations for: {'Grade': 'G5', 'Department': 'Engineering', 'Primary_Skill': 'Terraform', 'Secondary_Skill': 'Ansible', 'Course_Category': 'Cloud', 'Business_Priority': 'Critical', 'Career_Goal': 'Cloud Architect'}\n",
      "\n",
      "Top 3 Recommended Courses:\n",
      "1. AWS Cloud Practitioner\n",
      "   Category: Cloud\n",
      "   Confidence: 88.3%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_emp = {\n",
    "    'Grade': 'G5',\n",
    "    'Department': 'Engineering',\n",
    "    'Primary_Skill': 'Terraform',\n",
    "    'Secondary_Skill': 'Ansible',\n",
    "    'Course_Category': 'Cloud',\n",
    "    'Business_Priority': 'Critical',\n",
    "    'Career_Goal': 'Cloud Architect'\n",
    "}\n",
    "\n",
    "print(f\"Requesting recommendations for: {test_emp}\\n\")\n",
    "\n",
    "recs = recommend_course(test_emp, top_n=1)\n",
    "print(\"Top 3 Recommended Courses:\")\n",
    "for i, rec in enumerate(recs, 1):\n",
    "    print(f\"{i}. {rec['Course_Name']}\")\n",
    "    print(f\"   Category: {rec['Course_Category']}\")\n",
    "    print(f\"   Confidence: {rec['Confidence']:.1%}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "477ad646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 15 user profiles\n",
      "\n",
      "E901: Backend API Development (Category: Backend) | Matched\n",
      "E902: Machine Learning with Python (Category: Data Science) | Matched\n",
      "E903: Automated Testing with Selenium (Category: Testing) | Not Matched\n",
      "E904: AWS Cloud Practitioner (Category: Cloud) | Matched\n",
      "E905: Data Analysis and Visualization (Category: Analytics) | Matched\n",
      "E906: Backend API Development (Category: Backend) | Matched\n",
      "E907: Automated Testing with Selenium (Category: Testing) | Matched\n",
      "E908: DevOps and CI/CD Pipeline (Category: DevOps) | Matched\n",
      "E909: Data Pipeline Engineering (Category: Data Engineering) | Matched\n",
      "E910: Cybersecurity Essentials (Category: Security) | Matched\n",
      "E911: Backend API Development (Category: Backend) | Matched\n",
      "E912: Automated Testing with Selenium (Category: Testing) | Not Matched\n",
      "E913: Automated Testing with Selenium (Category: Testing) | Matched\n",
      "E914: Automated Testing with Selenium (Category: Testing) | Not Matched\n",
      "E915: Linux System Administration (Category: Infrastructure) | Matched\n",
      "Accuracy: 12/15 (80.0% matched)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load all user records from JSON and generate recommendations for each\n",
    "with open('test_employees.json', 'r') as f:\n",
    "    user_records = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(user_records)} user profiles\\n\")\n",
    "\n",
    "matched_count = 0\n",
    "total_count = 0\n",
    "\n",
    "for user in user_records:\n",
    "    display_name = user.get('Emp_Id') or user.get('Employee_Name', 'Unknown')\n",
    "    expected_course = user.get('Expected_Course', 'N/A')\n",
    "    \n",
    "    recommendations = recommend_course(user, top_n=1)\n",
    "    \n",
    "    if recommendations:\n",
    "        predicted_course = recommendations[0]['Course_Name']\n",
    "        course_category = recommendations[0]['Course_Category']\n",
    "        \n",
    "        if predicted_course == expected_course:\n",
    "            match_status = \"Matched\"\n",
    "            matched_count += 1\n",
    "        else:\n",
    "            match_status = \"Not Matched\"\n",
    "        \n",
    "        total_count += 1\n",
    "        \n",
    "        print(f\"{display_name}: {predicted_course} (Category: {course_category}) | {match_status}\")\n",
    "\n",
    "print(f\"Accuracy: {matched_count}/{total_count} ({matched_count/total_count*100:.1f}% matched)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
